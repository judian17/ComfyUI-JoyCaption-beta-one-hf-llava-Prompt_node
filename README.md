[中文版说明](README-ZH.md)

Since installing the GPU version of llama-cpp-python can be challenging, I have uploaded the [JoyCaption-beta-one-hf-llava-GGUF](https://huggingface.co/mradermacher/llama-joycaption-beta-one-hf-llava-GGUF) model to [Ollama](https://ollama.com/). You can now use [these models](https://ollama.com/aha2025/llama-joycaption-beta-one-hf-llava) by installing Ollama and the [ComfyUI-Ollama](https://github.com/stavsap/comfyui-ollama).

I have separated the prompt template used by the [ComfyUI-joycaption-beta-one-GGUF](https://github.com/judian17/ComfyUI-joycaption-beta-one-GGUF) node into this dedicated node. 

